{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "name": "FaceMask.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "34bec967-7b33-45ae-a0c5-389c1127afd6"
      ],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0d70bf9-1ba5-4b5a-a797-233d77d44feb"
      },
      "source": [
        "# FACE MASK DETECTION\n",
        "We detect users with mask or not based in dataset from:\n",
        " https://github.com/cabani/MaskedFace-Net \n"
      ],
      "id": "b0d70bf9-1ba5-4b5a-a797-233d77d44feb"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzDHMyobpJde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbe3fca8-5f60-47c3-bd33-aa74a55969ce"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\",force_remount=True)"
      ],
      "id": "vzDHMyobpJde",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6080c059-9ca3-4b13-b2a3-6390ff0345de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad275b70-219c-45cf-9dd9-a92326f52f3e"
      },
      "source": [
        "# UTILS + PREPROCESSING\n",
        "import os\n",
        "import imutils\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2 as cv2\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import skimage as sk\n",
        "from skimage import transform\n",
        "import copy\n",
        "import torch\n",
        "from tqdm.notebook import tqdm\n",
        "import re\n",
        "from PIL import Image\n",
        "import skimage.exposure as exposure\n",
        "\n",
        "!pip install mtcnn\n",
        "!pip install facenet_pytorch\n",
        "import mtcnn.mtcnn\n",
        "from facenet_pytorch import MTCNN\n",
        "\n",
        "main_path = '/content/drive/MyDrive/FaceMask/'\n",
        "\n",
        "#TORCH config\n",
        "name = 'PyTorch\\nGPU'\n",
        "torchdevice = 0\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda:{}'.format(torchdevice))\n",
        "else:\n",
        "    device = 'cpu'\n",
        "print('{} available: {}'.format(name, torch.cuda.is_available()))"
      ],
      "id": "6080c059-9ca3-4b13-b2a3-6390ff0345de",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mtcnn in /usr/local/lib/python3.7/dist-packages (0.1.1)\n",
            "Requirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from mtcnn) (2.7.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from mtcnn) (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python>=4.1.0->mtcnn) (1.19.5)\n",
            "Requirement already satisfied: facenet_pytorch in /usr/local/lib/python3.7/dist-packages (2.5.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from facenet_pytorch) (1.19.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from facenet_pytorch) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from facenet_pytorch) (2.23.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from facenet_pytorch) (0.11.1+cu111)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->facenet_pytorch) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->facenet_pytorch) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->facenet_pytorch) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->facenet_pytorch) (2.10)\n",
            "Requirement already satisfied: torch==1.10.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->facenet_pytorch) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10.0->torchvision->facenet_pytorch) (3.10.0.2)\n",
            "PyTorch\n",
            "GPU available: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34bec967-7b33-45ae-a0c5-389c1127afd6"
      },
      "source": [
        "## Collecting DATA + Preprocessing + Feature extraction\n",
        "We do the following:\n",
        "1. Collect the data\n",
        "2. Resize the images\n",
        "3. Denoise\n",
        "4. Extract features\n",
        "5. Create a dataframe with the data"
      ],
      "id": "34bec967-7b33-45ae-a0c5-389c1127afd6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2218aaae-cdd4-4f4d-a3c8-6b4924c1d98d"
      },
      "source": [
        "def process_img(image_path):\n",
        "    #parameter for size output szeXsze\n",
        "    sze = 224\n",
        "    #parameters for denoising\n",
        "    h=10\n",
        "    templateWindowSize=7\n",
        "    searchWindowSize=21\n",
        "    \n",
        "    #read+gray+resize+denoising\n",
        "    img = cv2.imread( image_path, cv2.IMREAD_GRAYSCALE )\n",
        "    #img = cv2.cvtColor( img, cv2.COLOR_BGR2GRAY)\n",
        "    img = cv2.resize( img, (sze,sze) )\n",
        "    img = cv2.fastNlMeansDenoising(img,None,h,templateWindowSize,searchWindowSize)\n",
        "    return img\n",
        "\n",
        "def feature_extraction(img):\n",
        "\n",
        "    #parameters for Gaussian blur\n",
        "    GBlur = 0\n",
        "    SBlur = 1.3\n",
        "    \n",
        "    #parameters for Sobel Edge detection\n",
        "    ksize_s = 3\n",
        "    \n",
        "    #parameters for Canny Edge detection\n",
        "    threshold1_c = 100\n",
        "    threshold2_c = 200\n",
        "    \n",
        "    \n",
        "    #Gaussian Blur\n",
        "    img_blur = cv2.GaussianBlur(img, (GBlur,GBlur), sigmaX=SBlur, sigmaY=SBlur )\n",
        "    \n",
        "    #Sobel Edge\n",
        "    sobelx = cv2.Sobel(src=img_blur, ddepth=cv2.CV_64F, dx=1, dy=0, ksize=ksize_s) # Sobel Edge Detection on the X axis\n",
        "    sobely = cv2.Sobel(src=img_blur, ddepth=cv2.CV_64F, dx=0, dy=1, ksize=ksize_s) # Sobel Edge Detection on the Y axis\n",
        "    sobelx2 = cv2.multiply(sobelx,sobelx)\n",
        "    sobely2 = cv2.multiply(sobely,sobely)\n",
        "    # add together and take square root\n",
        "    sobel_magnitude = cv2.sqrt(sobelx2 + sobely2)\n",
        "    # normalize to range 0 to 255 and clip negatives\n",
        "    sobel_magnitude = exposure.rescale_intensity(sobel_magnitude, in_range='image', out_range=(0,255)).clip(0,255).astype(np.uint8)\n",
        "        \n",
        "    #Canny Edge\n",
        "    canny = cv2.Canny(image=img_blur, threshold1=threshold1_c, threshold2=threshold1_c)\n",
        "    \n",
        "    #Laplacian of Gaussian\n",
        "    lap = cv2.Laplacian(img_blur, ddepth=cv2.CV_64F, ksize=ksize_s)\n",
        "    lap = cv2.convertScaleAbs(lap)\n",
        "    \n",
        "    return  {'LaofGau':lap, 'SobelEdgeXY':sobel_magnitude, 'CannyEdge':canny}\n",
        "\n",
        "#For plotting image\n",
        "def show( img ):\n",
        "    plt.imshow( img, cmap='gray' )\n",
        "    return"
      ],
      "id": "2218aaae-cdd4-4f4d-a3c8-6b4924c1d98d",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3308bf49-c218-4ed0-8272-356f8a31f6fe"
      },
      "source": [
        "#detect faces with mtcnn\n",
        "# we use this library after reading https://towardsdatascience.com/face-detection-models-which-to-use-and-why-d263e82c302c\n",
        "# info in https://www.kaggle.com/timesler/guide-to-mtcnn-in-facenet-pytorch#Bounding-boxes-and-facial-landmarks\n",
        "detector = mtcnn.mtcnn.MTCNN()\n",
        "def ReturnLocalizedFace( img ):\n",
        "    faces = detector.detect_faces( cv2.cvtColor( img, cv2.COLOR_GRAY2RGB ) )\n",
        "    return faces\n",
        "\n",
        "#for many faces\n",
        "def ReturnLocalizedManyFaces( manyimgs ):\n",
        "    detector = MTCNN( keep_all=True, device=device, post_process=False, select_largest=False)\n",
        "    imgs = []\n",
        "    for img in manyimgs:\n",
        "        img_p = cv2.copyMakeBorder(img, 20, 20, 20, 20, cv2.BORDER_CONSTANT) \n",
        "        imgs.append( Image.fromarray( cv2.cvtColor( img_p, cv2.COLOR_GRAY2RGB ) ) )\n",
        "    \n",
        "    cropped_imgs = detector( imgs )\n",
        "    \n",
        "    sol = []\n",
        "    for (img,ii) in zip(cropped_imgs,range(len(manyimgs))):\n",
        "        if img is None:\n",
        "            sol.append(manyimgs[ii])\n",
        "        else:\n",
        "            sol.append(cv2.resize(cv2.cvtColor( img.numpy()[0].T, cv2.COLOR_RGB2GRAY ).T,(224,224)))\n",
        "    return sol    \n",
        "    "
      ],
      "id": "3308bf49-c218-4ed0-8272-356f8a31f6fe",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56cfd49b-17ef-4bed-baf0-aa3e5855e273"
      },
      "source": [
        "CMFD_path = main_path + 'CMFD/'  #has 33 721 images\n",
        "IMFD_path = main_path + 'IMFD/'  #has 33 588 images\n",
        "max_subfolders = 2 #34\n",
        "\n",
        "def create_dataframe( in_path, out_path, max_subfolders, crop_images=False):\n",
        "    images = []\n",
        "    for (folder, ii)  in zip(glob.glob(in_path+'*'),range(max_subfolders)):\n",
        "        for image_path in glob.glob(folder+'/*.jpg'):\n",
        "            images.append( process_img(image_path) )      \n",
        "\n",
        "    if crop_images:\n",
        "        images = ReturnLocalizedManyFaces(images)\n",
        "    \n",
        "    df = {'Image':[], 'LaofGau':[], 'SobelEdgeXY':[], 'CannyEdge':[]}\n",
        "    for img in images:\n",
        "        feature = feature_extraction(img)\n",
        "        df['Image'].append(str(img.flatten().tolist()).replace(']','').replace('[',''))\n",
        "        for key in feature.keys():\n",
        "            df[key].append(str(feature[key].flatten().tolist()).replace(']','').replace('[',''))\n",
        "    \n",
        "    df = pd.DataFrame(df)\n",
        "    if re.search ('CMFD', in_path):\n",
        "        df['label'] = 0\n",
        "        compression_opts = dict(method='zip',\n",
        "                        archive_name='labels_0.csv')\n",
        "        df.to_csv(out_path+'/'+'labels_0.csv.zip', compression=compression_opts, index=False)\n",
        "    if re.search ('IMFD', in_path):\n",
        "        df['label'] = 1\n",
        "        compression_opts = dict(method='zip',\n",
        "                        archive_name='labels_1.csv')\n",
        "        df.to_csv(out_path+'/'+'labels_1.csv.zip', compression=compression_opts, index=False)\n",
        "    \n",
        "    return df        \n"
      ],
      "id": "56cfd49b-17ef-4bed-baf0-aa3e5855e273",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16aa5210-1064-4e73-985d-fe9a7cfdb928",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e57319a-cbdc-46d2-e2f5-c1af4223e266"
      },
      "source": [
        "if os.path.exists(CMFD_path+'/labels_0.csv.zip'):\n",
        "    print(\"load CMFD csv file\")\n",
        "    df_C = pd.read_csv( CMFD_path+'/labels_0.csv.zip' )\n",
        "else:\n",
        "    print(\"create CMFD csv file\")\n",
        "    df_C = create_dataframe( CMFD_path, CMFD_path, max_subfolders)\n",
        "    \n",
        "if os.path.exists(IMFD_path+'/labels_1.csv.zip'):\n",
        "    print(\"load IMFD csv file\")\n",
        "    df_I = pd.read_csv( IMFD_path+'/labels_1.csv.zip' )\n",
        "else:\n",
        "    print(\"create IMFD csv file\")\n",
        "    df_I = create_dataframe( IMFD_path, IMFD_path, max_subfolders)\n",
        "    \n",
        "df = pd.concat([df_I, df_C], axis=0, ignore_index=True).sample(frac=1)\n",
        "df_C = None\n",
        "df_I = None"
      ],
      "id": "16aa5210-1064-4e73-985d-fe9a7cfdb928",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load CMFD csv file\n",
            "load IMFD csv file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f403f16c-606b-414d-b03e-35d565d36052"
      },
      "source": [
        "## Training the models\n",
        "Based in: \n",
        "  https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html and \n",
        "  https://github.com/sheldonsebastian/face_mask_detector/tree/main/Code "
      ],
      "id": "f403f16c-606b-414d-b03e-35d565d36052"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "554da4b2-89b4-42d0-a371-1871954e5d60"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision import models\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset\n",
        "import torch.optim \n",
        "import time"
      ],
      "id": "554da4b2-89b4-42d0-a371-1871954e5d60",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95ba7c19-fbaa-439a-841e-c571de24445b"
      },
      "source": [
        "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
        "model_name = \"resnet18\"\n",
        "\n",
        "# Number of classes in the dataset\n",
        "num_classes = 2\n",
        "\n",
        "# Batch size for training (change depending on how much memory you have)\n",
        "batch_size = 128  #bigger 8 is good for df.sample(frac=0.1) \n",
        "\n",
        "# Number of epochs to train for\n",
        "num_epochs = 15\n",
        "\n",
        "# Parameter for Adam Optimizer\n",
        "LR = 0.001\n",
        "\n",
        "# Flag for feature extracting. When False, we finetune the whole model,\n",
        "#   when True we only update the reshaped layer params\n",
        "feature_extract = True"
      ],
      "id": "95ba7c19-fbaa-439a-841e-c571de24445b",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaa72673-4bd8-42f1-abb6-e1574101ebbf"
      },
      "source": [
        "The training algorithm"
      ],
      "id": "eaa72673-4bd8-42f1-abb6-e1574101ebbf"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0883dd07-981d-4939-8400-a956205f2db1",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
        "    since = time.time()\n",
        "\n",
        "    val_acc_history = []\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for loader_dat  in dataloaders[phase]:\n",
        "                inputs = loader_dat.inp\n",
        "                labels = loader_dat.tgt\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # Get model outputs and calculate loss\n",
        "                    # Special case for inception because in training it has an auxiliary output. In train\n",
        "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
        "                    #   but in testing we only consider the final output.\n",
        "                    if is_inception and phase == 'train':\n",
        "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
        "                        outputs, aux_outputs = model(inputs)\n",
        "                        loss1 = criterion(outputs, labels)\n",
        "                        loss2 = criterion(aux_outputs, labels)\n",
        "                        loss = loss1 + 0.4*loss2\n",
        "                    else:\n",
        "                        outputs = model(inputs)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data[:,1]) #torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history, optimizer"
      ],
      "id": "0883dd07-981d-4939-8400-a956205f2db1",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb7958ac-cd9e-4a9f-872d-15624d6220db"
      },
      "source": [
        "The model to load/use "
      ],
      "id": "eb7958ac-cd9e-4a9f-872d-15624d6220db"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36e9afec-96c0-4895-8761-1c64cb884735",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "# %% --------------------\n",
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    # feature_extract_param = True means all layers frozen except the last user added layers\n",
        "    # feature_extract_param = False means all layers unfrozen and entire network learns new weights\n",
        "    # and biases\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "            \n",
        "\n",
        "# %% --------------------initialize pretrained model & return input size desired by pretrained model\n",
        "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
        "    # Initialize these variables which will be set in this if statement. Each of these\n",
        "    #   variables is model specific.\n",
        "    model_ft = None\n",
        "    input_size = 0\n",
        "\n",
        "    if model_name == \"resnet18\":\n",
        "        \"\"\" Resnet18\n",
        "        \"\"\"\n",
        "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"resnet50\":\n",
        "        \"\"\" Resnet50\n",
        "        \"\"\"\n",
        "        model_ft = models.resnet50(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Sequential(nn.Dropout(0.3), nn.Linear(num_ftrs, num_classes))\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"alexnet\":\n",
        "        \"\"\" Alexnet\n",
        "        \"\"\"\n",
        "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"vgg\":\n",
        "        \"\"\" VGG11_bn\n",
        "        \"\"\"\n",
        "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"squeezenet\":\n",
        "        \"\"\" Squeezenet\n",
        "        \"\"\"\n",
        "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1, 1), stride=(1, 1))\n",
        "        model_ft.num_classes = num_classes\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"densenet\":\n",
        "        \"\"\" Densenet\n",
        "        \"\"\"\n",
        "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier.in_features\n",
        "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"inception\":\n",
        "        \"\"\" Inception v3\n",
        "        Be careful, expects (299,299) sized images and has auxiliary output\n",
        "        \"\"\"\n",
        "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        # Handle the auxilary net\n",
        "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
        "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        # Handle the primary net\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 299\n",
        "\n",
        "    else:\n",
        "        print(\"Invalid model name, exiting...\")\n",
        "        exit()\n",
        "\n",
        "    return model_ft, input_size\n",
        "\n"
      ],
      "id": "36e9afec-96c0-4895-8761-1c64cb884735",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "350c2841-a863-4797-a361-00436c47393f"
      },
      "source": [
        "Data set Loading"
      ],
      "id": "350c2841-a863-4797-a361-00436c47393f"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "658083e0-22ee-4541-9433-cab6f934274f",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "def get_tensordataset(df, feature, transform=None):\n",
        "    imgs = []\n",
        "    labels = []\n",
        "    for img_p, label in zip(df[feature],df['label']):\n",
        "        img_p = np.array(img_p.split(', ')).astype(np.uint8).reshape( (224,224) )\n",
        "        image = Image.fromarray( cv2.cvtColor( img_p, cv2.COLOR_GRAY2RGB ) )\n",
        "        if transform:\n",
        "            image = transform(image)\n",
        "        else:\n",
        "            generic_transformer = transforms.Compose([\n",
        "                transforms.Resize(224),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "            image = generic_transformer(image)\n",
        "        if label == 0:    \n",
        "          labels.append( torch.Tensor( [ 1, 0 ] ) )\n",
        "        if label == 1:\n",
        "          labels.append( torch.Tensor( [ 0, 1 ] ) )\n",
        "        imgs.append(image)\n",
        "    \n",
        "    a = torch.stack(imgs)\n",
        "    b = torch.stack(labels) \n",
        "    \n",
        "    return TensorDataset(a.view(a.shape),b.view(b.shape))\n",
        "\n",
        "class SimpleCustomBatch:\n",
        "    def __init__(self, data):\n",
        "        transposed_data = list(zip(*data))\n",
        "        self.inp = torch.stack(transposed_data[0], 0)\n",
        "        self.tgt = torch.stack(transposed_data[1], 0)\n",
        "\n",
        "    # custom memory pinning method on custom type\n",
        "    def pin_memory(self):\n",
        "        self.inp = self.inp.pin_memory()\n",
        "        self.tgt = self.tgt.pin_memory()\n",
        "        return self\n",
        "\n",
        "def collate_wrapper(batch):\n",
        "    return SimpleCustomBatch(batch)"
      ],
      "id": "658083e0-22ee-4541-9433-cab6f934274f",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1771d45b-49a3-42d0-92d5-7452007ac3ac",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "def find_model_feature( feature, df_train, df_val ):\n",
        "    if feature not in ['Image', 'LaofGau', 'SobelEdgeXY', 'CannyEdge'] :\n",
        "        print('Bad feature name')\n",
        "        return \n",
        "\n",
        "    # Initialize the model for this run\n",
        "    model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
        "\n",
        "    # Print the model we just instantiated\n",
        "    #print(model_ft)\n",
        "\n",
        "\n",
        "    # Send the model to GPU\n",
        "    model_ft = model_ft.to(device)\n",
        "\n",
        "    # Gather the parameters to be optimized/updated in this run. If we are\n",
        "    #  finetuning we will be updating all parameters. However, if we are\n",
        "    #  doing feature extract method, we will only update the parameters\n",
        "    #  that we have just initialized, i.e. the parameters with requires_grad\n",
        "    #  is True.\n",
        "    params_to_update = model_ft.parameters()\n",
        "    print(\"Params to learn:\")\n",
        "    if feature_extract:\n",
        "        params_to_update = []\n",
        "        for name,param in model_ft.named_parameters():\n",
        "            if param.requires_grad == True:\n",
        "                params_to_update.append(param)\n",
        "                print(\"\\t\",name)\n",
        "    else:\n",
        "        for name,param in model_ft.named_parameters():\n",
        "            if param.requires_grad == True:\n",
        "                print(\"\\t\",name)\n",
        "    \n",
        "\n",
        "    # %% --------------------\n",
        "    optimizer_ft = torch.optim.Adam(params_to_update, lr=LR)\n",
        "    \n",
        "    \n",
        "    # Setup the loss fxn\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    \n",
        "    # Load data TODO\n",
        "    # some augmentation\n",
        "    train_transformer = transforms.Compose([\n",
        "        transforms.Resize(input_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.ColorJitter(saturation=[0, 1]),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "    # validation and holdout transformation is generic\n",
        "    # normalization and resize\n",
        "    generic_transformer = transforms.Compose([\n",
        "        transforms.Resize(input_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "    # create dataloader\n",
        "    \n",
        "        \n",
        "    train_dataset = get_tensordataset(df_train, feature, transform=train_transformer)\n",
        "    val_dataset = get_tensordataset(df_val, feature, transform=generic_transformer)\n",
        "    \n",
        "    train_dataloader = DataLoader(train_dataset,batch_size=batch_size, collate_fn=collate_wrapper, pin_memory=True )\n",
        "    val_dataloader = DataLoader(val_dataset,batch_size=batch_size, collate_fn=collate_wrapper, pin_memory=True )\n",
        "\n",
        "    # create dataloader dictionary\n",
        "    dataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader}\n",
        "\n",
        "    # Train and evaluate\n",
        "    print('Training feature: '+feature )\n",
        "    model, hist, optim = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))\n",
        "\n",
        "    \n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    return model, hist, optim"
      ],
      "id": "1771d45b-49a3-42d0-92d5-7452007ac3ac",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c39f695-ca07-4d8c-b7c5-c8565315e524",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a592ad0d-fecf-41f1-bbde-ff9cb5d8f493"
      },
      "source": [
        "models_list = []\n",
        "hist_list = []\n",
        "df1 = df #df.sample(frac=0.1)\n",
        "df_train, df2 = train_test_split(df1,test_size=0.4,random_state=2)\n",
        "df_val, df_test = train_test_split(df2,test_size=0.5,random_state=2)\n",
        "print('train size ',df_train.count()[0])\n",
        "print('validation size ',df_val.count()[0])\n",
        "print('test size ',df_test.count()[0])\n",
        "feature_list = ['Image', 'LaofGau', 'SobelEdgeXY', 'CannyEdge']\n",
        "for feature in feature_list:\n",
        "    print('\\n\\n #####  Starting feature ', feature,' #####\\n\\n')\n",
        "    sol1, sol2, sol3 = find_model_feature(feature,df_train,df_val)\n",
        "    models_list.append(sol1)\n",
        "    hist_list.append(sol2)"
      ],
      "id": "3c39f695-ca07-4d8c-b7c5-c8565315e524",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train size  2310\n",
            "validation size  770\n",
            "test size  771\n",
            "\n",
            "\n",
            " #####  Starting feature  Image  #####\n",
            "\n",
            "\n",
            "Params to learn:\n",
            "\t fc.weight\n",
            "\t fc.bias\n",
            "Training feature: Image\n",
            "Epoch 0/14\n",
            "----------\n",
            "train Loss: 0.6590 Acc: 0.6100\n",
            "val Loss: 0.5216 Acc: 0.7935\n",
            "\n",
            "Epoch 1/14\n",
            "----------\n",
            "train Loss: 0.4441 Acc: 0.8463\n",
            "val Loss: 0.3985 Acc: 0.8623\n",
            "\n",
            "Epoch 2/14\n",
            "----------\n",
            "train Loss: 0.3522 Acc: 0.8831\n",
            "val Loss: 0.3302 Acc: 0.8948\n",
            "\n",
            "Epoch 3/14\n",
            "----------\n",
            "train Loss: 0.3036 Acc: 0.8991\n",
            "val Loss: 0.2843 Acc: 0.9104\n",
            "\n",
            "Epoch 4/14\n",
            "----------\n",
            "train Loss: 0.2738 Acc: 0.9061\n",
            "val Loss: 0.2583 Acc: 0.9273\n",
            "\n",
            "Epoch 5/14\n",
            "----------\n",
            "train Loss: 0.2528 Acc: 0.9113\n",
            "val Loss: 0.2404 Acc: 0.9286\n",
            "\n",
            "Epoch 6/14\n",
            "----------\n",
            "train Loss: 0.2371 Acc: 0.9173\n",
            "val Loss: 0.2270 Acc: 0.9299\n",
            "\n",
            "Epoch 7/14\n",
            "----------\n",
            "train Loss: 0.2247 Acc: 0.9208\n",
            "val Loss: 0.2164 Acc: 0.9351\n",
            "\n",
            "Epoch 8/14\n",
            "----------\n",
            "train Loss: 0.2145 Acc: 0.9229\n",
            "val Loss: 0.2077 Acc: 0.9351\n",
            "\n",
            "Epoch 9/14\n",
            "----------\n",
            "train Loss: 0.2059 Acc: 0.9238\n",
            "val Loss: 0.2006 Acc: 0.9390\n",
            "\n",
            "Epoch 10/14\n",
            "----------\n",
            "train Loss: 0.1985 Acc: 0.9247\n",
            "val Loss: 0.1945 Acc: 0.9403\n",
            "\n",
            "Epoch 11/14\n",
            "----------\n",
            "train Loss: 0.1921 Acc: 0.9264\n",
            "val Loss: 0.1894 Acc: 0.9416\n",
            "\n",
            "Epoch 12/14\n",
            "----------\n",
            "train Loss: 0.1864 Acc: 0.9281\n",
            "val Loss: 0.1849 Acc: 0.9442\n",
            "\n",
            "Epoch 13/14\n",
            "----------\n",
            "train Loss: 0.1813 Acc: 0.9299\n",
            "val Loss: 0.1811 Acc: 0.9442\n",
            "\n",
            "Epoch 14/14\n",
            "----------\n",
            "train Loss: 0.1766 Acc: 0.9307\n",
            "val Loss: 0.1777 Acc: 0.9468\n",
            "\n",
            "Training complete in 0m 33s\n",
            "Best val Acc: 0.946753\n",
            "\n",
            "\n",
            " #####  Starting feature  LaofGau  #####\n",
            "\n",
            "\n",
            "Params to learn:\n",
            "\t fc.weight\n",
            "\t fc.bias\n",
            "Training feature: LaofGau\n",
            "Epoch 0/14\n",
            "----------\n",
            "train Loss: 0.6547 Acc: 0.6043\n",
            "val Loss: 0.6325 Acc: 0.6364\n",
            "\n",
            "Epoch 1/14\n",
            "----------\n",
            "train Loss: 0.5205 Acc: 0.7775\n",
            "val Loss: 0.5603 Acc: 0.7156\n",
            "\n",
            "Epoch 2/14\n",
            "----------\n",
            "train Loss: 0.4520 Acc: 0.8225\n",
            "val Loss: 0.4958 Acc: 0.7636\n",
            "\n",
            "Epoch 3/14\n",
            "----------\n",
            "train Loss: 0.4114 Acc: 0.8429\n",
            "val Loss: 0.4483 Acc: 0.7909\n",
            "\n",
            "Epoch 4/14\n",
            "----------\n",
            "train Loss: 0.3836 Acc: 0.8550\n",
            "val Loss: 0.4129 Acc: 0.8195\n",
            "\n",
            "Epoch 5/14\n",
            "----------\n",
            "train Loss: 0.3631 Acc: 0.8641\n",
            "val Loss: 0.3944 Acc: 0.8312\n",
            "\n",
            "Epoch 6/14\n",
            "----------\n",
            "train Loss: 0.3470 Acc: 0.8719\n",
            "val Loss: 0.3820 Acc: 0.8364\n",
            "\n",
            "Epoch 7/14\n",
            "----------\n",
            "train Loss: 0.3338 Acc: 0.8762\n",
            "val Loss: 0.3723 Acc: 0.8429\n",
            "\n",
            "Epoch 8/14\n",
            "----------\n",
            "train Loss: 0.3227 Acc: 0.8801\n",
            "val Loss: 0.3643 Acc: 0.8468\n",
            "\n",
            "Epoch 9/14\n",
            "----------\n",
            "train Loss: 0.3133 Acc: 0.8840\n",
            "val Loss: 0.3578 Acc: 0.8468\n",
            "\n",
            "Epoch 10/14\n",
            "----------\n",
            "train Loss: 0.3051 Acc: 0.8883\n",
            "val Loss: 0.3522 Acc: 0.8481\n",
            "\n",
            "Epoch 11/14\n",
            "----------\n",
            "train Loss: 0.2978 Acc: 0.8944\n",
            "val Loss: 0.3475 Acc: 0.8506\n",
            "\n",
            "Epoch 12/14\n",
            "----------\n",
            "train Loss: 0.2914 Acc: 0.8978\n",
            "val Loss: 0.3434 Acc: 0.8519\n",
            "\n",
            "Epoch 13/14\n",
            "----------\n",
            "train Loss: 0.2856 Acc: 0.8978\n",
            "val Loss: 0.3399 Acc: 0.8506\n",
            "\n",
            "Epoch 14/14\n",
            "----------\n",
            "train Loss: 0.2803 Acc: 0.8991\n",
            "val Loss: 0.3368 Acc: 0.8545\n",
            "\n",
            "Training complete in 0m 33s\n",
            "Best val Acc: 0.854545\n",
            "\n",
            "\n",
            " #####  Starting feature  SobelEdgeXY  #####\n",
            "\n",
            "\n",
            "Params to learn:\n",
            "\t fc.weight\n",
            "\t fc.bias\n",
            "Training feature: SobelEdgeXY\n",
            "Epoch 0/14\n",
            "----------\n",
            "train Loss: 0.5780 Acc: 0.7078\n",
            "val Loss: 0.6625 Acc: 0.5727\n",
            "\n",
            "Epoch 1/14\n",
            "----------\n",
            "train Loss: 0.4403 Acc: 0.8260\n",
            "val Loss: 0.5394 Acc: 0.6948\n",
            "\n",
            "Epoch 2/14\n",
            "----------\n",
            "train Loss: 0.3855 Acc: 0.8511\n",
            "val Loss: 0.3757 Acc: 0.8532\n",
            "\n",
            "Epoch 3/14\n",
            "----------\n",
            "train Loss: 0.3543 Acc: 0.8667\n",
            "val Loss: 0.3311 Acc: 0.8909\n",
            "\n",
            "Epoch 4/14\n",
            "----------\n",
            "train Loss: 0.3328 Acc: 0.8758\n",
            "val Loss: 0.3118 Acc: 0.8883\n",
            "\n",
            "Epoch 5/14\n",
            "----------\n",
            "train Loss: 0.3164 Acc: 0.8870\n",
            "val Loss: 0.2994 Acc: 0.8922\n",
            "\n",
            "Epoch 6/14\n",
            "----------\n",
            "train Loss: 0.3031 Acc: 0.8961\n",
            "val Loss: 0.2896 Acc: 0.8935\n",
            "\n",
            "Epoch 7/14\n",
            "----------\n",
            "train Loss: 0.2921 Acc: 0.8983\n",
            "val Loss: 0.2817 Acc: 0.8961\n",
            "\n",
            "Epoch 8/14\n",
            "----------\n",
            "train Loss: 0.2828 Acc: 0.9035\n",
            "val Loss: 0.2752 Acc: 0.8987\n",
            "\n",
            "Epoch 9/14\n",
            "----------\n",
            "train Loss: 0.2747 Acc: 0.9065\n",
            "val Loss: 0.2698 Acc: 0.9000\n",
            "\n",
            "Epoch 10/14\n",
            "----------\n",
            "train Loss: 0.2675 Acc: 0.9087\n",
            "val Loss: 0.2651 Acc: 0.9039\n",
            "\n",
            "Epoch 11/14\n",
            "----------\n",
            "train Loss: 0.2612 Acc: 0.9113\n",
            "val Loss: 0.2612 Acc: 0.9052\n",
            "\n",
            "Epoch 12/14\n",
            "----------\n",
            "train Loss: 0.2555 Acc: 0.9130\n",
            "val Loss: 0.2577 Acc: 0.9052\n",
            "\n",
            "Epoch 13/14\n",
            "----------\n",
            "train Loss: 0.2503 Acc: 0.9147\n",
            "val Loss: 0.2547 Acc: 0.9065\n",
            "\n",
            "Epoch 14/14\n",
            "----------\n",
            "train Loss: 0.2456 Acc: 0.9152\n",
            "val Loss: 0.2521 Acc: 0.9065\n",
            "\n",
            "Training complete in 0m 33s\n",
            "Best val Acc: 0.906494\n",
            "\n",
            "\n",
            " #####  Starting feature  CannyEdge  #####\n",
            "\n",
            "\n",
            "Params to learn:\n",
            "\t fc.weight\n",
            "\t fc.bias\n",
            "Training feature: CannyEdge\n",
            "Epoch 0/14\n",
            "----------\n",
            "train Loss: 0.6602 Acc: 0.6195\n",
            "val Loss: 0.5919 Acc: 0.7065\n",
            "\n",
            "Epoch 1/14\n",
            "----------\n",
            "train Loss: 0.5381 Acc: 0.7619\n",
            "val Loss: 0.4882 Acc: 0.7909\n",
            "\n",
            "Epoch 2/14\n",
            "----------\n",
            "train Loss: 0.4721 Acc: 0.8043\n",
            "val Loss: 0.4592 Acc: 0.8039\n",
            "\n",
            "Epoch 3/14\n",
            "----------\n",
            "train Loss: 0.4344 Acc: 0.8281\n",
            "val Loss: 0.4208 Acc: 0.8377\n",
            "\n",
            "Epoch 4/14\n",
            "----------\n",
            "train Loss: 0.4087 Acc: 0.8403\n",
            "val Loss: 0.4005 Acc: 0.8429\n",
            "\n",
            "Epoch 5/14\n",
            "----------\n",
            "train Loss: 0.3901 Acc: 0.8463\n",
            "val Loss: 0.3866 Acc: 0.8519\n",
            "\n",
            "Epoch 6/14\n",
            "----------\n",
            "train Loss: 0.3758 Acc: 0.8563\n",
            "val Loss: 0.3763 Acc: 0.8481\n",
            "\n",
            "Epoch 7/14\n",
            "----------\n",
            "train Loss: 0.3644 Acc: 0.8619\n",
            "val Loss: 0.3684 Acc: 0.8545\n",
            "\n",
            "Epoch 8/14\n",
            "----------\n",
            "train Loss: 0.3550 Acc: 0.8632\n",
            "val Loss: 0.3621 Acc: 0.8532\n",
            "\n",
            "Epoch 9/14\n",
            "----------\n",
            "train Loss: 0.3471 Acc: 0.8667\n",
            "val Loss: 0.3571 Acc: 0.8532\n",
            "\n",
            "Epoch 10/14\n",
            "----------\n",
            "train Loss: 0.3403 Acc: 0.8688\n",
            "val Loss: 0.3530 Acc: 0.8558\n",
            "\n",
            "Epoch 11/14\n",
            "----------\n",
            "train Loss: 0.3345 Acc: 0.8697\n",
            "val Loss: 0.3495 Acc: 0.8558\n",
            "\n",
            "Epoch 12/14\n",
            "----------\n",
            "train Loss: 0.3293 Acc: 0.8714\n",
            "val Loss: 0.3467 Acc: 0.8558\n",
            "\n",
            "Epoch 13/14\n",
            "----------\n",
            "train Loss: 0.3247 Acc: 0.8727\n",
            "val Loss: 0.3443 Acc: 0.8558\n",
            "\n",
            "Epoch 14/14\n",
            "----------\n",
            "train Loss: 0.3205 Acc: 0.8732\n",
            "val Loss: 0.3422 Acc: 0.8597\n",
            "\n",
            "Training complete in 0m 33s\n",
            "Best val Acc: 0.859740\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "269c4e6c-81fd-4ae0-9d83-df65d6033de0"
      },
      "source": [
        "## The union of models"
      ],
      "id": "269c4e6c-81fd-4ae0-9d83-df65d6033de0"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZJkm_tDtvVp"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "id": "hZJkm_tDtvVp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgAXDf2ERfxJ"
      },
      "source": [
        "def _find_new_coordinates( df_l, model_i, feature ):\n",
        "    model_i.eval()\n",
        "    acc_dataset = get_tensordataset( df_l, feature)    \n",
        "    acc_dataloader = DataLoader( acc_dataset,batch_size=batch_size, collate_fn=collate_wrapper, pin_memory=True )\n",
        "\n",
        "    pred = []\n",
        "    actual = []\n",
        "    coord = []\n",
        "\n",
        "    # get all outputs\n",
        "    for loader_dat  in acc_dataloader:\n",
        "        inputs = loader_dat.inp\n",
        "        labels = loader_dat.tgt\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        with torch.no_grad():\n",
        "            # logit\n",
        "            predictions = model_i(inputs)\n",
        "\n",
        "            # find index with max logit\n",
        "            val, index = torch.max(predictions, 1)\n",
        "\n",
        "            # append prediction\n",
        "            pred.extend(index.tolist())\n",
        "\n",
        "            # append actual\n",
        "            actual.extend(labels.data[:,1].tolist())\n",
        "\n",
        "            # append coordinates\n",
        "            coord.extend( predictions.tolist() )\n",
        "\n",
        "    accuracy = accuracy_score(actual, pred)\n",
        "    f1 = f1_score(actual, pred, average='micro')\n",
        "    cm = confusion_matrix(actual, pred)\n",
        "    print(\"Accuracy::\" + str(accuracy))\n",
        "    print(\"F1 Score::\" + str(f1))\n",
        "    print(\"Confusion Matrix::\" + str(cm))\n",
        "\n",
        "    return coord, pred, actual"
      ],
      "id": "pgAXDf2ERfxJ",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlLnF0KzWlMO"
      },
      "source": [
        "def find_new_coordinates( df, stringi ):\n",
        "  print('\\nCalculating in data set '+stringi.upper())\n",
        "  coords = []\n",
        "  preds = []\n",
        "  actuals = []\n",
        "  for ii in range(4):\n",
        "    print('\\nResults for ', feature_list[ii])\n",
        "    coord, pred, actual = _find_new_coordinates( df, models_list[ii], feature_list[ii] )\n",
        "    if ii == 0 :\n",
        "      coords = coord\n",
        "      preds = [ [ll] for ll in pred ]\n",
        "      actuals = [ int(ll) for ll in actual ]\n",
        "    else:\n",
        "      for ii in range(len(coord)):\n",
        "        coords[ii].extend(coord[ii])\n",
        "        preds[ii].append(pred[ii])\n",
        "   \n",
        "  return {'coords_'+stringi:coords, 'preds_'+stringi:preds, 'actuals_'+stringi:actuals}        "
      ],
      "id": "KlLnF0KzWlMO",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XwQf-PBZH-4",
        "outputId": "40653bf2-e33f-4ea2-e844-000e5838df6b"
      },
      "source": [
        "test_coords = find_new_coordinates(df_test,'test')\n",
        "train_coords = find_new_coordinates(df_train,'train')\n",
        "val_coords = find_new_coordinates(df_val,'val')"
      ],
      "id": "9XwQf-PBZH-4",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Calculating in data set TEST\n",
            "\n",
            "Results for  Image\n",
            "Accuracy::0.9325551232166018\n",
            "F1 Score::0.9325551232166018\n",
            "Confusion Matrix::[[367  32]\n",
            " [ 20 352]]\n",
            "\n",
            "Results for  LaofGau\n",
            "Accuracy::0.8599221789883269\n",
            "F1 Score::0.8599221789883269\n",
            "Confusion Matrix::[[345  54]\n",
            " [ 54 318]]\n",
            "\n",
            "Results for  SobelEdgeXY\n",
            "Accuracy::0.8715953307392996\n",
            "F1 Score::0.8715953307392996\n",
            "Confusion Matrix::[[357  42]\n",
            " [ 57 315]]\n",
            "\n",
            "Results for  CannyEdge\n",
            "Accuracy::0.8573281452658884\n",
            "F1 Score::0.8573281452658884\n",
            "Confusion Matrix::[[351  48]\n",
            " [ 62 310]]\n",
            "\n",
            "Calculating in data set TRAIN\n",
            "\n",
            "Results for  Image\n",
            "Accuracy::0.9337662337662338\n",
            "F1 Score::0.9337662337662338\n",
            "Confusion Matrix::[[1057   88]\n",
            " [  65 1100]]\n",
            "\n",
            "Results for  LaofGau\n",
            "Accuracy::0.8982683982683982\n",
            "F1 Score::0.8982683982683982\n",
            "Confusion Matrix::[[1030  115]\n",
            " [ 120 1045]]\n",
            "\n",
            "Results for  SobelEdgeXY\n",
            "Accuracy::0.90995670995671\n",
            "F1 Score::0.90995670995671\n",
            "Confusion Matrix::[[1052   93]\n",
            " [ 115 1050]]\n",
            "\n",
            "Results for  CannyEdge\n",
            "Accuracy::0.8748917748917749\n",
            "F1 Score::0.8748917748917749\n",
            "Confusion Matrix::[[1011  134]\n",
            " [ 155 1010]]\n",
            "\n",
            "Calculating in data set VAL\n",
            "\n",
            "Results for  Image\n",
            "Accuracy::0.9467532467532468\n",
            "F1 Score::0.9467532467532468\n",
            "Confusion Matrix::[[363  17]\n",
            " [ 24 366]]\n",
            "\n",
            "Results for  LaofGau\n",
            "Accuracy::0.8545454545454545\n",
            "F1 Score::0.8545454545454545\n",
            "Confusion Matrix::[[329  51]\n",
            " [ 61 329]]\n",
            "\n",
            "Results for  SobelEdgeXY\n",
            "Accuracy::0.9064935064935065\n",
            "F1 Score::0.9064935064935065\n",
            "Confusion Matrix::[[348  32]\n",
            " [ 40 350]]\n",
            "\n",
            "Results for  CannyEdge\n",
            "Accuracy::0.8597402597402597\n",
            "F1 Score::0.8597402597402598\n",
            "Confusion Matrix::[[321  59]\n",
            " [ 49 341]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "849a356a-54b4-445a-9d2b-ddb7ea701153"
      },
      "source": [
        "def theFifthClassifier( test_coords, train_coords, val_coords ):\n",
        "  df_test = np.array(test_coords['coords_test'])\n",
        "  df_test_l = np.array(test_coords['actuals_test'])\n",
        "\n",
        "  df_train = np.vstack( (np.array(train_coords['coords_train']), np.array(val_coords['coords_val']) ) )\n",
        "  df_train_l = np.hstack( (np.array(train_coords['actuals_train']), np.array(val_coords['actuals_val']) ) )\n",
        "\n",
        "\n",
        "  classif = KNeighborsClassifier(n_neighbors=8)\n",
        "  def ClassifierFunction( ):\n",
        "    return classif.fit( df_train, df_train_l )\n",
        "  \n",
        "  print( '######################' )\n",
        "  print( 'Training' )\n",
        "  classificated = ClassifierFunction( )\n",
        "  print( '...' )                           \n",
        "  print( 'Testing' )\n",
        "  pred = classificated.predict(df_test)\n",
        "  actual = df_test_l\n",
        "  accuracy = accuracy_score(actual, pred)\n",
        "  f1 = f1_score(actual, pred, average='micro')\n",
        "  cm = confusion_matrix(actual, pred)\n",
        "  print(\"The Fifht classifier\")\n",
        "  print(\"Accuracy::\" + str(accuracy))\n",
        "  print(\"F1 Score::\" + str(f1))\n",
        "  print(\"Confusion Matrix::\" + str(cm))\n",
        "\n",
        "  final_pred = []\n",
        "  for ii in range(len(pred)):\n",
        "    test_coords['preds_test'][ii].append(pred[ii])\n",
        "    sol = np.sum(np.array(test_coords['preds_test'][ii]))\n",
        "    if sol>=3:\n",
        "      final_pred.append(1)\n",
        "    else:\n",
        "      final_pred.append(0)  \n",
        "\n",
        "  accuracy = accuracy_score(actual, final_pred)\n",
        "  f1 = f1_score(actual, final_pred, average='micro')\n",
        "  cm = confusion_matrix(actual, final_pred)\n",
        "  print(\"The Final prediction\")\n",
        "  print(\"Accuracy::\" + str(accuracy))\n",
        "  print(\"F1 Score::\" + str(f1))\n",
        "  print(\"Confusion Matrix::\" + str(cm))\n",
        "\n",
        "  return"
      ],
      "id": "849a356a-54b4-445a-9d2b-ddb7ea701153",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSe547h0j94w",
        "outputId": "e40f76fd-d524-4949-fc72-1e9362dc3aae"
      },
      "source": [
        "theFifthClassifier( test_coords, train_coords, val_coords )\n"
      ],
      "id": "qSe547h0j94w",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "######################\n",
            "Training\n",
            "...\n",
            "Testing\n",
            "The Fifht classifier\n",
            "Accuracy::0.9455252918287937\n",
            "F1 Score::0.9455252918287937\n",
            "Confusion Matrix::[[389  10]\n",
            " [ 32 340]]\n",
            "The Final prediction\n",
            "Accuracy::0.9416342412451362\n",
            "F1 Score::0.9416342412451362\n",
            "Confusion Matrix::[[387  12]\n",
            " [ 33 339]]\n"
          ]
        }
      ]
    }
  ]
}